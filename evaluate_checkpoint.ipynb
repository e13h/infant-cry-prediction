{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<a href=\"https://colab.research.google.com/github/evanphilipsmith/infant-cry-prediction/blob/main/evaluate_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Dependencies and Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ ! -f utils.py ] && wget https://raw.githubusercontent.com/evanphilipsmith/infant-cry-prediction/main/utils.py\n",
    "![ ! -f dataset.py ] && wget https://raw.githubusercontent.com/evanphilipsmith/infant-cry-prediction/main/dataset.py\n",
    "![ ! -f network.py ] && wget https://raw.githubusercontent.com/evanphilipsmith/infant-cry-prediction/main/network.py\n",
    "![ ! -f pretrained_model.pth ] && wget https://raw.githubusercontent.com/evanphilipsmith/infant-cry-prediction/main/pretrained_model.pth\n",
    "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "![ ! -d donateacry-corpus ] && git clone https://github.com/gveres/donateacry-corpus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import load_checkpoint, evaluate\n",
    "from dataset import DonateACryDataset\n",
    "\n",
    "assert torch.cuda.is_available(), \"Select a GPU from Runtime -> Change runtime type\""
   ]
  },
  {
   "source": [
    "# Evaluate Checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dirs = ['./donateacry-corpus/donateacry_corpus_cleaned_and_updated_data/']\n",
    "clean_test_data = DonateACryDataset(clean_dirs, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/92 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "clean_test_loader = DataLoader(clean_test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "loss = CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bar = tqdm(total=len(clean_test_loader), position=0, leave=True)\n",
    "\n",
    "saved_model = load_checkpoint('pretrained_model.pth', dir='./').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/92 [00:06<?, ?it/s]\n",
      "evaluating: 100%|██████████| 92/92 [00:36<00:00,  2.73it/s]"
     ]
    }
   ],
   "source": [
    "losses, accuracies, preds = evaluate(saved_model, clean_test_loader, loss, device, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num epochs trained 136\nmicro: 0.8478260869565218\nmacro: 0.6595959595959596\ndistribution of preds: (array([0, 1, 2, 3, 4]), array([ 7,  4, 77,  1,  3]))\n"
     ]
    }
   ],
   "source": [
    "print('num epochs trained', saved_model.num_epochs_trained)\n",
    "print('micro:', f1_score(clean_test_data.data.target, preds, average='micro'))\n",
    "print('macro:', f1_score(clean_test_data.data.target, preds, average='macro'))\n",
    "print('distribution of preds:', np.unique(preds, return_counts=True))"
   ]
  }
 ]
}